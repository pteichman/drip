#!/usr/bin/env python3

import argparse
import copy
import io
import os
import sys
import urllib.request
import xml.etree.ElementTree

# This only supports RSS 2.0 feeds. So far, I have been able to find one of
# those (vs Atom or earlier RSS) for everything I've wanted to drip.


def main():
    parser = argparse.ArgumentParser(
        prog="drip", description="A slow trickle podcast republisher"
    )

    parser.add_argument("-o", required=True, help="output filename")
    parser.add_argument("-i", required=True, help="input feed url")
    parser.add_argument("-n", type=int, default=1, help="number of items to republish")
    args = parser.parse_args()

    feed = fetch(args.i)
    src = xml.etree.ElementTree.parse(io.BytesIO(feed))

    latest_seen = None
    if os.path.exists(args.o):
        seen = xml.etree.ElementTree.parse(args.o)
        latest_item = seen.find("channel/item")
        if latest_item is not None:
            latest_seen = rss_item_key(latest_item)

    src_index = find_index(src, latest_seen)
    dst_skips = max(0, src_index - args.n)

    # drip `args.n` more items than we'd already seen into `dst`.
    dst = xml.etree.ElementTree.parse(io.BytesIO(feed))
    dst_channel = dst.find("channel")
    for _ in range(dst_skips):
        dst_channel.remove(dst_channel.find("item"))

    # update the feed title to reflect the number of items published.
    src_count = rss_numitems(src)
    dst_count = rss_numitems(dst)

    dst_title = dst.find("channel/title")
    dst_title.text = "[drip %0.2f%%] %s" % (
        100 * float(dst_count) / src_count,
        dst_title.text,
    )

    dst.write(args.o, xml_declaration=True)


# find_index returns the index of the item with `key` in feed, or the index
# after the last item if not found.
def find_index(feed, key):
    items = feed.findall("channel/item")
    for i, item in enumerate(items):
        if rss_item_key(item) == key:
            return i
    return len(items)


def rss_item_key(item):
    tag = item.find("guid")
    if tag is not None:
        return tag.text

    tag = item.find("enclosure")
    return tag.get("url")


def rss_numitems(feed):
    return len(feed.findall("channel/item"))


def fetch(url):
    req = urllib.request.Request(url)
    req.add_header("Accept", "application/rss+xml")
    req.add_header("User-Agent", "drip/1.0")

    resp = urllib.request.urlopen(req)
    return resp.read()


if __name__ == "__main__":
    main()
